{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a RAG to predit risk score of a transaction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiating model using groq inference server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"GROQ_API_KEY\"):\n",
    "  os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter API key for Groq: \")\n",
    "\n",
    "os.environ[\"NEO4J_URI\"] = \"bolt://localhost:7687\"\n",
    "os.environ[\"NEO4J_USERNAME\"] = \"neo4j\"\n",
    "os.environ[\"NEO4J_PASSWORD\"] = \"Anish@hack1\"\n",
    "\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"qwen-2.5-coder-32b\", model_provider=\"groq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple prompt with SystemMessage and HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='To predict the risk score for the transaction of transferring 10 rupees from Wells Fargo to Microsoft, we need to consider several factors, such as the amount, the entities involved, the purpose, and the context. Here’s a breakdown:\\n\\n### Factors to Consider:\\n1. **Amount:** The transaction amount is very small (10 rupees), which typically does not pose a significant risk in terms of financial fraud.\\n2. **Entities Involved:** Wells Fargo is a reputable financial institution, and Microsoft is a well-known technology company with a strong financial standing.\\n3. **Purpose:** Without additional context, the purpose of this transaction is unclear. If this transaction is part of a legitimate business relationship, it would likely have a lower risk.\\n4. **Context:** There is no additional context provided, such as frequency, historical transactions, or the relationship between the two entities.\\n\\n### Predicted Risk Score:\\n- **Risk Score:** 0.02\\n- **Confidence Score:** 0.85\\n- **Reason:** The transaction amount is extremely small, which makes it unlikely to be involved in financial fraud. Both entities are large, reputable institutions, and there is no additional information suggesting any irregularity or suspicious behavior.\\n\\n### Summary:\\n- **Risk Score:** 0.02\\n- **Confidence Score:** 0.85\\n- **Reason:** The transaction is between two reputable entities and involves a minimal amount, suggesting a low risk of fraud or other financial irregularities.\\n\\nIf there is any additional context or details about this transaction, such as the purpose or frequency, please provide them for a more accurate risk assessment.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 335, 'prompt_tokens': 93, 'total_tokens': 428, 'completion_time': 1.675, 'prompt_time': 0.008160904, 'queue_time': 0.078421197, 'total_time': 1.683160904}, 'model_name': 'qwen-2.5-coder-32b', 'system_fingerprint': 'fp_8c499b07d0', 'finish_reason': 'stop', 'logprobs': None}, id='run-a668df40-ee57-4724-9164-54f7b1c23401-0', usage_metadata={'input_tokens': 93, 'output_tokens': 335, 'total_tokens': 428})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# transaction = input('Enter transaction: ')\n",
    "\n",
    "# messages = [\n",
    "#     SystemMessage(\"You are an assitant that helps data analysts in a financial institution to risk score a transaction among entities/corporations. It can also include individuals. Given an input transaction, you need to predict the risk score (0 to 1) of the transaction, confidence score (0 to 1) and a reason for the risk score.\"),\n",
    "#     HumanMessage(transaction),\n",
    "# ]\n",
    "\n",
    "# model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Chain with prompt (chatprompttemplate) and context (wikipedia retriever) and model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wikipedia Retriever "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import WikipediaRetriever\n",
    "\n",
    "# documentloader \n",
    "wiki_retriever = WikipediaRetriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs = wiki_retriever.invoke(\"Adani Green Energy\")\n",
    "# for doc in docs:\n",
    "#     print(doc)\n",
    "#     print(\"===\")\n",
    "\n",
    "# print(docs[2].page_content[:400])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# prompt = ChatPromptTemplate.from_template(\n",
    "#     \"\"\"\n",
    "#     You are an agent that helps data analysts in a financial institution by risk scoring a transaction \n",
    "#     among entities/corporations. It can also include individuals. Given an input transaction, you need to output \n",
    "#     the risk score (0 to 1) of the transaction, confidence score (0 to 1). Use the context if needed.\n",
    "#     Context: {context}\n",
    "#     Transaction: {transaction}\n",
    "#     \"\"\"\n",
    "# )\n",
    "\n",
    "\n",
    "# def format_docs(docs):\n",
    "#     return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# chain = (\n",
    "#     {\"context\": wiki_retriever | format_docs, \"transaction\": RunnablePassthrough()}\n",
    "#     | prompt\n",
    "#     | model\n",
    "#     | StrOutputParser()\n",
    "# )\n",
    "# # chain = (\n",
    "# #     {\"context\": retriever, \"transaction\": RunnablePassthrough()},\n",
    "# #     | prompt\n",
    "# #     | model\n",
    "# #     | StrOutputParser()\n",
    "# # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # transaction_test = input()\n",
    "# chain.invoke(\n",
    "#     \"Transaction ID: TXN20250322113045, Date: 2025-03-22T11:30:45Z,  Payer: Tesla, Inc.  Payer Account Number: TESLA987654321,  Payer Bank: JPMorgan Chase Bank, USA, Payee: Adani Green Energy Ltd.  ,Payee Account Number: ADANIGREEN123456  ,Payee Bank: State Bank of India, India  ,Amount: 500,000,000 USD  ,Payment Method: Wire Transfer  ,Purpose: Investment in Renewable Energy Collaboration  ,Status: Completed  \"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_neo4j import Neo4jGraph\n",
    "\n",
    "# graph = Neo4jGraph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph.refresh_schema()\n",
    "# print(graph.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enhanced_graph = Neo4jGraph(enhanced_schema=True)\n",
    "# print(enhanced_graph.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Note: Sometimes this may return an error. It depends on the how well the llm is able to generate the cypher query. \n",
    "# ## Few-shot prompting is one way to improve the performance of the llm.\n",
    "# from langchain_neo4j import GraphCypherQAChain\n",
    "\n",
    "# chain = GraphCypherQAChain.from_llm(\n",
    "#     graph=enhanced_graph, llm=model, verbose=True, allow_dangerous_requests=True, validate_cypher=True\n",
    "# )\n",
    "# response = chain.invoke({\"query\": \"Name the officers that are linked with French entities\"})\n",
    "# print(response) # response becomes context \n",
    "\n",
    "\n",
    "# ## Input: Transaction -> Process the input to extract entities and generate a prompt to generate a query -> Query the graph database to get the required information and store it -> Pass this along with Wikipedia retriever to generate the risk_score and confidence score \n",
    "# ## Should we use separate chains? Is it possible to use one chain to do all of this?\n",
    "\n",
    "# ## Output: Risk Score, Confidence Score, Reason for the risk score\n",
    "\n",
    "# ## catching error, timeout ,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "api_key = input(\"Enter your OpenSanctions API Key: \")\n",
    "os.environ[\"OPENSANCTIONS_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pprint import pprint\n",
    "# import requests\n",
    "# import os\n",
    "\n",
    "# OS_API_KEY = os.getenv(\"OPENSANCTIONS_API_KEY\")\n",
    "# if not OS_API_KEY:\n",
    "#     raise ValueError(\"The OS_API_KEY environment variable is not set\")\n",
    "\n",
    "# def fetch_sanctions_data(person_name, company_name):\n",
    "#     headers = {\"Authorization\": OS_API_KEY}\n",
    "\n",
    "#     query = {\n",
    "#         \"queries\": {\n",
    "#             \"query-A\": {\"schema\": \"Person\", \"properties\": {\"name\": [person_name]}},\n",
    "#             \"query-B\": {\"schema\": \"Company\", \"properties\": {\"name\": [company_name]}},\n",
    "#         }\n",
    "#     }\n",
    "\n",
    "#     response = requests.post(\n",
    "#         \"https://api.opensanctions.org/match/default\", headers=headers, json=query\n",
    "#     )\n",
    "#     response.raise_for_status()\n",
    "#     response_json = response.json()\n",
    "\n",
    "#     print(\"\\nFull API Response:\")\n",
    "#     pprint(response_json, sort_dicts=False)\n",
    "\n",
    "#     # Define known risky datasets\n",
    "#     risky_datasets = {\n",
    "#         \"us_ofac_sdn\", \"eu_travel_bans\", \"gb_hmt_sanctions\", \"ua_nsdc_sanctions\",\n",
    "#         \"eu_fsf\", \"lt_fiu_freezes\", \"ca_dfatd_sema_sanctions\", \"jp_mof_sanctions\",\n",
    "#         \"ch_seco_sanctions\", \"ru_acf_bribetakers\", \"be_fod_sanctions\", \"au_dfat_sanctions\"\n",
    "#     }\n",
    "    \n",
    "#     for query_id, query_response in response_json[\"responses\"].items():\n",
    "#         print(f\"\\nResults for query {query_id}:\")\n",
    "#         results = []\n",
    "        \n",
    "#         for result in query_response[\"results\"]:\n",
    "#             entity_info = {\n",
    "#                 \"id\": result[\"id\"],\n",
    "#                 \"name\": result[\"properties\"].get(\"name\", []),\n",
    "#                 \"match\": result[\"match\"],\n",
    "#                 \"topics\": result[\"properties\"].get(\"topics\", []),\n",
    "#                 \"datasets\": result.get(\"datasets\", []),\n",
    "#             }\n",
    "#             results.append(entity_info)\n",
    "\n",
    "#         pprint(results, sort_dicts=False)\n",
    "\n",
    "#         # **Improved Risk Detection**\n",
    "#         risky_entities = []\n",
    "#         for entity in results:\n",
    "#             entity_topics = set(entity.get(\"topics\", []))\n",
    "#             entity_datasets = set(entity.get(\"datasets\", []))\n",
    "\n",
    "#             if entity_topics.intersection({\"sanction\", \"pep\", \"crime\", \"corruption\", \"terrorism\"}) or \\\n",
    "#                entity_datasets.intersection(risky_datasets):\n",
    "#                 risky_entities.append(entity)\n",
    "\n",
    "#         if risky_entities:\n",
    "#             print(\"\\n🚨 Risky Entities Detected:\")\n",
    "#             pprint(risky_entities, sort_dicts=False)\n",
    "#         else:\n",
    "#             print(\"\\n✅ No risky entities found.\")\n",
    "\n",
    "# # Example Usage:\n",
    "# fetch_sanctions_data(\"Vladimir Putin\", \"\")\n",
    "\n",
    "\n",
    "\n",
    "# # \"name\": result[\"properties\"].get(\"name\", []),\n",
    "#                     # \"match\": result[\"match\"],\n",
    "#                     # \"topics\": list(entity_topics),  \n",
    "#                     # \"datasets\": list(entity_datasets),  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pprint import pprint\n",
    "# import requests\n",
    "# import os\n",
    "\n",
    "# OS_API_KEY = os.getenv(\"OPENSANCTIONS_API_KEY\")\n",
    "# if not OS_API_KEY:\n",
    "#     raise ValueError(\"The OS_API_KEY environment variable is not set\")\n",
    "\n",
    "# def fetch_sanctions_data(person_name, company_name):\n",
    "#     headers = {\"Authorization\": OS_API_KEY}\n",
    "\n",
    "#     query = {\n",
    "#         \"queries\": {\n",
    "#             \"query-A\": {\"schema\": \"Person\", \"properties\": {\"name\": [person_name]}},\n",
    "#             \"query-B\": {\"schema\": \"Company\", \"properties\": {\"name\": [company_name]}},\n",
    "#         }\n",
    "#     }\n",
    "\n",
    "#     response = requests.post(\n",
    "#         \"https://api.opensanctions.org/match/default\", headers=headers, json=query\n",
    "#     )\n",
    "#     response.raise_for_status()\n",
    "#     response_json = response.json()\n",
    "\n",
    "#     print(\"\\nFull API Response:\")\n",
    "#     pprint(response_json, sort_dicts=False)\n",
    "\n",
    "#     # Define known risky datasets and topics\n",
    "#     risky_datasets = {\n",
    "#     \"eu_travel_bans\", \"gb_hmt_sanctions\", \"ua_nsdc_sanctions\", \"jp_mof_sanctions\",\n",
    "#     \"ca_dfatd_sema_sanctions\", \"ch_seco_sanctions\", \"lt_fiu_freezes\", \"au_dfat_sanctions\",\n",
    "#     \"us_ofac_sdn\", \"ru_acf_bribetakers\", \"be_fod_sanctions\", \"eu_fsf\",\n",
    "#     \"in_nse_debarred\"  # ✅ Added NSE debarred list\n",
    "# }\n",
    "\n",
    "\n",
    "#     risky_topics = {\"wanted\", \"sanction\", \"poi\", \"corruption\", \"crime\", \"role.pep\", \"terrorism\", \"reg.warn\"}\n",
    "\n",
    "\n",
    "#     for query_id, query_response in response_json[\"responses\"].items():\n",
    "#         print(f\"\\nResults for query {query_id}:\")\n",
    "#         results = []\n",
    "        \n",
    "#         for result in query_response[\"results\"]:\n",
    "#             entity_topics = set(result[\"properties\"].get(\"topics\", []))  # Fix extraction\n",
    "#             entity_datasets = set(result.get(\"datasets\", []))  # Fix extraction\n",
    "\n",
    "#             print(f\"\\n🔎 Checking Entity: {result['id']}\")\n",
    "#             print(f\"📌 Topics: {entity_topics}\")\n",
    "#             print(f\"📌 Datasets: {entity_datasets}\")\n",
    "\n",
    "#             entity_info = {\n",
    "#                 \"id\": result[\"id\"],\n",
    "#                 \"name\": result[\"properties\"].get(\"name\", []),\n",
    "#                 \"match\": result[\"match\"],\n",
    "#                 \"topics\": list(entity_topics),  \n",
    "#                 \"datasets\": list(entity_datasets),  \n",
    "#             }\n",
    "#             results.append(entity_info)\n",
    "\n",
    "#         pprint(results, sort_dicts=False)\n",
    "\n",
    "#         # **Improved Risk Detection**\n",
    "#         risky_entities = []\n",
    "#         for entity in results:\n",
    "#             entity_topics = set(entity[\"topics\"])\n",
    "#             entity_datasets = set(entity[\"datasets\"])\n",
    "\n",
    "#             print(f\"\\n🧐 Checking Risk for {entity['id']}:\")\n",
    "#             print(f\"🟡 Entity Topics: {entity_topics}\")\n",
    "#             print(f\"🟡 Risky Topics: {risky_topics}\")\n",
    "#             print(f\"🔹 Matching Topics: {entity_topics.intersection(risky_topics)}\")\n",
    "\n",
    "#             print(f\"🟢 Entity Datasets: {entity_datasets}\")\n",
    "#             print(f\"🟢 Risky Datasets: {risky_datasets}\")\n",
    "#             print(f\"🔸 Matching Datasets: {entity_datasets.intersection(risky_datasets)}\")\n",
    "\n",
    "#             if entity_topics.intersection(risky_topics) or entity_datasets.intersection(risky_datasets):\n",
    "#                 risky_entities.append(entity)\n",
    "\n",
    "#         if risky_entities:\n",
    "#             print(\"\\n🚨 Risky Entities Detected:\")\n",
    "#             pprint(risky_entities, sort_dicts=False)\n",
    "#         else:\n",
    "#             print(\"\\n✅ No risky entities found.\")\n",
    "\n",
    "# # Example Usage:\n",
    "# fetch_sanctions_data(\"\",  \"Adani Green Energy Ltd.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#added changes to the branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from langchain.schema.document import Document\n",
    "from langchain.schema.retriever import BaseRetriever\n",
    "\n",
    "class OpenSanctionsRetriever(BaseRetriever):\n",
    "\n",
    "    def _get_relevant_documents(self, query):\n",
    "        \"\"\"\n",
    "        Queries OpenSanctions API and returns relevant documents.\n",
    "        \"\"\"\n",
    "\n",
    "        person_name=\"\"\n",
    "        company_name=\"\"\n",
    "        api_key = \"3b9678eb2e0dff14c268b43f7acf4798\"\n",
    "        if \"Company:\" in query or \"Person:\" in query:\n",
    "            parts = query.split(\",\")\n",
    "            for part in parts:\n",
    "                if \"Company:\" in part:\n",
    "                    company_name = part.split(\"Company:\")[-1].strip()\n",
    "                    print(company_name)\n",
    "                elif \"Person:\" in part:\n",
    "                    person_name = part.split(\"Person:\")[-1].strip()\n",
    "                    print(person_name)\n",
    "\n",
    "\n",
    "        headers = {\"Authorization\": api_key}\n",
    "        # params = {\"q\": query}\n",
    "\n",
    "        query = {\n",
    "            \"queries\": {\n",
    "                \"query-A\": {\"schema\": \"Person\", \"properties\": {\"name\": [person_name]}},\n",
    "                \"query-B\": {\"schema\": \"Company\", \"properties\": {\"name\": [company_name]}},\n",
    "            }\n",
    "        }\n",
    "        response = requests.post(\n",
    "            \"https://api.opensanctions.org/match/default\", headers=headers, json=query\n",
    "        )\n",
    "        # if response.status_code != 200:\n",
    "        #     return []\n",
    "        \n",
    "        response.raise_for_status()\n",
    "        response_json = response.json()\n",
    "\n",
    "        # print(\"\\nFull API Response:\")\n",
    "        # pprint(response_json, sort_dicts=False)\n",
    "\n",
    "        # if not response_json.get(\"results\"):\n",
    "        #     print(\"empty list lool\")\n",
    "        #     return []\n",
    "\n",
    "        documents = []\n",
    "        # print(\"outside first for\")\n",
    "        for query_id, query_response in response_json[\"responses\"].items():\n",
    "            # print(f\"\\nResults for query {query_id}:\")\n",
    "            # results = []\n",
    "            \n",
    "            for result in query_response[\"results\"]:\n",
    "                # print(\"in for result\")\n",
    "                entity_topics = set(result[\"properties\"].get(\"topics\", []))  # Fix extraction\n",
    "                entity_datasets = set(result.get(\"datasets\", []))  # Fix extraction\n",
    "\n",
    "                # print(f\"\\n🔎 Checking Entity: {result['id']}\")\n",
    "                # print(f\"📌 Topics: {entity_topics}\")\n",
    "                # print(f\"📌 Datasets: {entity_datasets}\")\n",
    "                \n",
    "                name_to_store_page_content=result[\"properties\"].get(\"name\")\n",
    "                # print(\"hehe\", name_to_store_page_content[0])\n",
    "                entity_info = {\n",
    "                    \"id\": result[\"id\"],\n",
    "                    \"name\": result[\"properties\"].get(\"name\", []),\n",
    "                    \"match\": result[\"match\"],\n",
    "                    \"topics\": list(entity_topics),  \n",
    "                    \"datasets\": list(entity_datasets),  \n",
    "                }\n",
    "                doc = Document(page_content=f\"Sanctions data for {name_to_store_page_content}\", metadata=entity_info)\n",
    "                # print(\"doc = \", doc)\n",
    "                documents.append(doc)\n",
    "                # results.append(entity_info)\n",
    "        return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "OpenSanctions_retriever = OpenSanctionsRetriever()\n",
    "# sanction_docs = OpenSanctions_retriever._get_relevant_documents(\"Company: Adani Green Energy Ltd., Person: Adani\")\n",
    "# print(\"sanction_docs = \", sanction_docs)\n",
    "# # print(sanction_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for doc in sanction_docs:\n",
    "#     print(doc)\n",
    "#     print(\"===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs = ensemble_retriever.invoke(\"Company: Adani Green Energy Ltd., Person: Adani\")\n",
    "# docs\n",
    "# # for doc in docs:\n",
    "# #     print(doc.metadata)\n",
    "# #     print(doc.page_content)\n",
    "# #     print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/n743976x54b5sf64vktc7md40000gn/T/ipykernel_17730/999324814.py:10: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Step 1: Load and vectorize Instructions.md\n",
    "loader = TextLoader(\"Instructions.md\")\n",
    "docs = loader.load()\n",
    "\n",
    "# Use a local embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Store Instructions.md in FAISS and create a retriever\n",
    "vectorstore = FAISS.from_documents(docs, embedding_model)\n",
    "instructions_retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[wiki_retriever, OpenSanctions_retriever, instructions_retriever], weights=[0.25, 0.5, 0.25]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "prompt_test = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are an agent that helps data analysts in a financial institution by risk scoring a transaction \n",
    "    among entities/corporations. It can also include individuals. Given an input transaction, you need to output \n",
    "    the risk score (0 to 1) of the transaction, confidence score (0 to 1) and reason for your answer.\n",
    "    Context: {context}\n",
    "    Transaction: {transaction}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "chain_test = (\n",
    "    {\"context\": ensemble_retriever | format_docs, \"transaction\": RunnablePassthrough()}\n",
    "    | prompt_test\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided transaction details, let\\'s perform the risk scoring analysis:\\n\\n### **Extracted Key Information**\\n\\n1. **Key Entity Information:**\\n   - **Sender:** Tesla, Inc.\\n     - **Entity Type:** Corporation\\n     - **Account Number:** TESLA987654321\\n   - **Receiver:** Adani Green Energy Ltd.\\n     - **Entity Type:** Corporation\\n     - **Account Number:** ADANIGREEN123456\\n   - **Intermediary Bank:** JPMorgan Chase Bank, USA\\n   - **Final Bank:** State Bank of India, India\\n\\n2. **Transaction Details:**\\n   - **Amount:** 500,000,000 USD\\n   - **Transaction Type:** Wire Transfer\\n   - **Purpose:** Investment in Renewable Energy Collaboration\\n   - **Completion Time:** 2025-03-22T11:30:45Z\\n\\n3. **Additional Risk Indicators:**\\n   - **Intermediaries & Routing:** The transaction involves a US bank (JPMorgan Chase) and an Indian bank (State Bank of India).\\n   - **Sanctions/Watchlists:** Tesla, Inc. and Adani Green Energy Ltd. need to be checked against sanctions lists.\\n   - **Country Risk:** India is considered a somewhat high-risk jurisdiction for financial transactions due to its involvement in several high-profile investigations and regulatory issues.\\n   - **Transaction Patterns:** The transaction amount is significant, but the purpose seems legitimate (Investment in Renewable Energy Collaboration).\\n\\n### **Risk Analysis**\\n\\n1. **Sanctioned Entity Involvement**\\n   - **Risk Weight:** 1.0\\n   - **Confidence Score:** 0.2 (Neither Tesla nor Adani Green Energy Ltd. appears on major sanctions lists, but Adani Group has faced scrutiny, so some caution is warranted.)\\n   - **Reason:** No direct involvement found on major sanctions lists, but Adani Group has faced regulatory scrutiny.\\n\\n2. **Shell Company Activity**\\n   - **Risk Weight:** 0.9\\n   - **Confidence Score:** 0.1 (No indications of shell company activity found for either entity.)\\n   - **Reason:** No known shell company associations for Tesla or Adani Green Energy Ltd.\\n\\n3. **Politically Exposed Person (PEP) Involvement**\\n   - **Risk Weight:** 0.8\\n   - **Confidence Score:** 0.1 (No PEP involvement found in available records.)\\n   - **Reason:** Neither entity shows any connection to known PEPs.\\n\\n4. **Unusual Transaction Patterns**\\n   - **Risk Weight:** 0.7\\n   - **Confidence Score:** 0.4 (The transaction amount is large, but the purpose seems legitimate.)\\n   - **Reason:** Large transaction amount, but the stated purpose appears valid.\\n\\n5. **High-Risk Jurisdiction**\\n   - **Risk Weight:** 0.6\\n   - **Confidence Score:** 0.5 (India is considered a high-risk jurisdiction.)\\n   - **Reason:** India is listed as a high-risk jurisdiction by some financial regulators.\\n\\n6. **Lack of Transparency**\\n   - **Risk Weight:** 0.5\\n   - **Confidence Score:** 0.2 (No clear evidence of missing documents or forged information.)\\n   - **Reason:** No indication of missing or forged documents.\\n\\n7. **Use of Intermediaries in High-Risk Locations**\\n   - **Risk Weight:** 0.4\\n   - **Confidence Score:** 0.1 (No unnecessary intermediaries detected.)\\n   - **Reason:** The transaction uses a US bank and an Indian bank, both of which are reputable.\\n\\n8. **Mismatch Between Entity Type & Transaction**\\n   - **Risk Weight:** 0.3\\n   - **Confidence Score:** 0.1 (No mismatch found between entity types and transaction purpose.)\\n   - **Reason:** The transaction purpose aligns with the entity types (both are corporations involved in investment).\\n\\n9. **VPN or Proxy Usage**\\n   - **Risk Weight:** 0.2\\n   - **Confidence Score:** 0.1 (No VPN or proxy usage detected.)\\n   - **Reason:** No evidence of VPN or proxy usage in the transaction details.\\n\\n10. **Minor Inconsistencies**\\n    - **Risk Weight:** 0.1\\n    - **Confidence Score:** 0.1 (No minor inconsistencies found.)\\n    - **Reason:** No minor inconsistencies found in the provided data.\\n\\n### **Risk Score Calculation**\\n\\n\\\\[\\n\\\\text{Risk Score} = \\\\frac{(1.0 \\\\times 0.2) + (0.9 \\\\times 0.1) + (0.8 \\\\times 0.1) + (0.7 \\\\times 0.4) + (0.6 \\\\times 0.5) + (0.5 \\\\times 0.2) + (0.4 \\\\times 0.1) + (0.3 \\\\times 0.1) + (0.2 \\\\times 0.1) + (0.1 \\\\times 0.1)}{10}\\n\\\\]\\n\\n\\\\[\\n\\\\text{Risk Score} = \\\\frac{0.2 + 0.09 + 0.08 + 0.28 + 0.3 + 0.1 + 0.04 + 0.03 + 0.02 + 0.01}{10} = \\\\frac{1.15}{10} = 0.115\\n\\\\]\\n\\n### **Final Confidence Score Calculation**\\n\\n\\\\[\\n\\\\text{Final Confidence Score} = \\\\frac{0.2 + 0.1 + 0.1 + 0.4 + 0.5 + 0.2 + 0.1 + 0.1 + 0.1 + 0.1}{10} = \\\\frac{2.0}{10} = 0.2\\n\\\\]\\n\\n### **Transaction Classification**\\n\\n- **Risk Score:** 0.115\\n- **Final Confidence Score:** 0.2\\n- **Risk Category:** Minimal Risk\\n- **Action:** No action needed.\\n\\n### **Output JSON**\\n\\n```json\\n{\\n  \"Transaction ID\": \"TXN20250322113045\",\\n  \"Extracted Entity\": [\"Tesla, Inc.\", \"Adani Green Energy Ltd.\"],\\n  \"Entity Type\": [\"Corporation\", \"Corporation\"],\\n  \"Risk Score\": 0.115,\\n  \"Supporting Evidence\": [\"OFAC Sanctions List\", \"Company Website\", \"Global Financial Integrity Report\"],\\n  \"Confidence Score\": 0.2,\\n  \"Reason\": \"No direct involvement in sanctioned entities, no shell company activity, no PEP connections, and the transaction amount is large but the purpose is legitimate. India is a high-risk jurisdiction, but there\\'s no strong evidence of illicit activity.\",\\n  \"Transaction Classification\": \"Minimal Risk\",\\n  \"Conclusion\": \"The transaction involves entities from a high-risk jurisdiction, but there is no direct evidence of involvement in illicit activities. The minimal risk score of 0.115 indicates no immediate action is required.\"\\n}\\n```\\n\\nThis analysis concludes that the transaction is categorized under minimal risk, requiring no immediate action, but the high-risk jurisdiction of India warrants continued monitoring.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_test.invoke(\"TXN20250322113045,2025-03-22T11:30:45Z,Tesla, Inc.,TESLA987654321,JPMorgan Chase Bank, USA,Adani Green Energy Ltd.,ADANIGREEN123456,State Bank of India, India,500000000,USD,Wire Transfer,Investment in Renewable Energy Collaboration,Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lcai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
